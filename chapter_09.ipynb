{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9章 潜在顧客を把握するための画像認識10本ノック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下準備として，データのあるディレクトリに移動しておく\n",
    "import os\n",
    "\n",
    "DATA_ROOT_DIR = \"./sample/9章/\"\n",
    "os.chdir(DATA_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ノック81 画像データを読み込んでみよう\n",
    "まずはデータを読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "画像幅: 1920\n画像高さ: 1440\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "img = cv2.imread(\"img/img01.jpg\")\n",
    "height, width = img.shape[:2]\n",
    "print(\"画像幅: \" + str(width))\n",
    "print(\"画像高さ: \" + str(height))\n",
    "\n",
    "# display(Image(\"img/img01.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ノック８２：映像データを読み込んでみよう\n",
    "やはりデータを読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "画像幅: 1920.0\n画像高さ: 1440.0\n総フレーム数: 401.0\nFPS: 30.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import Video, display, YouTubeVideo, HTML\n",
    "\n",
    "# 情報取得\n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"画像幅: \" + str(width))\n",
    "print(\"画像高さ: \" + str(height))\n",
    "print(\"総フレーム数: \" + str(count))\n",
    "print(\"FPS: \" + str(fps))\n",
    "\n",
    "# 出力\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret:\n",
    "#         cv2.imshow(\"frame\", frame)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# display(Video(\"mov/mov01.avi\", embed=True))"
   ]
  },
  {
   "source": [
    "## ノック83 映像を画像に分割し、保存してみよう\n",
    "動画から画像を切り抜く\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "num = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # cv2.imshow(\"frame\", frame)\n",
    "        filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n",
    "        if not os.path.exists(filepath):\n",
    "            cv2.imwrite(filepath,frame)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "    else:\n",
    "        break\n",
    "    num = num + 1\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## ノック84 画像内のどこに人がいるのかを検出してみよう\n",
    "HOG特徴量を利用して人の検出を行う．"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 準備\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "# 検出\n",
    "img = cv2.imread(\"img/img01.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "if (len(human)>0):\n",
    "    for (x, y, w, h) in human:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255,255,255), 3)\n",
    "# cv2.imshow(\"img\",img)\n",
    "_ = cv2.imwrite(\"temp.jpg\",img)\n",
    "# display(Image(\"temp.jpg\"))"
   ]
  },
  {
   "source": [
    "## ノック85 画像内の人の顔を検出してみよう\n",
    "Haar-like特徴量を利用して顔検出を行う．"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# 準備\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# 検出\n",
    "img = cv2.imread(\"img/img02.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_list = cascade.detectMultiScale(gray, minSize=(50, 50))\n",
    "\n",
    "for (x, y, w, h) in face_list:\n",
    "    color = (0, 0, 225)\n",
    "    pen_w = 3\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, thickness = pen_w)\n",
    "\n",
    "# cv2.imshow(\"img\",img)\n",
    "_ = cv2.imwrite(\"temp.jpg\",img)\n",
    "# cv2.waitKey(0)\n",
    "# display(Image(\"temp.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}